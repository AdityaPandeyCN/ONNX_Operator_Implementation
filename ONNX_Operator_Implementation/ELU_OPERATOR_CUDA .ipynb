{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5bngexl1dqV",
        "outputId": "d74cae7d-472e-49d0-d730-828654230d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root_v6.30.04_Ubunt 100%[===================>] 272.11M  34.2MB/s    in 7.9s    \n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "g++ set to manually installed.\n",
            "gcc is already the newest version (4:11.2.0-1ubuntu1).\n",
            "gcc set to manually installed.\n",
            "gfortran is already the newest version (4:11.2.0-1ubuntu1).\n",
            "libxext-dev is already the newest version (2:1.3.4-1build1).\n",
            "libxext-dev set to manually installed.\n",
            "libxft-dev is already the newest version (2.3.4-1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "dpkg-dev is already the newest version (1.21.1ubuntu2.3).\n",
            "dpkg-dev set to manually installed.\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "libx11-dev is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-dev set to manually installed.\n",
            "tar is already the newest version (1.34+dfsg-1ubuntu0.1.22.04.2).\n",
            "libpython3.11-dev is already the newest version (3.11.11-1+jammy1).\n",
            "libpython3.11-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  binutils-common binutils-x86-64-linux-gnu libapr1 libaprutil1 libbinutils libctf0 libserf-1-1\n",
            "  libsvn1 libutf8proc2\n",
            "Suggested packages:\n",
            "  binutils-doc db5.3-util libapache2-mod-svn subversion-tools\n",
            "The following NEW packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1 libutf8proc2 libxpm-dev subversion\n",
            "The following packages will be upgraded:\n",
            "  binutils binutils-common binutils-x86-64-linux-gnu libbinutils libctf0\n",
            "5 upgraded, 7 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 6,080 kB of archives.\n",
            "After this operation, 10.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf0 amd64 2.38-4ubuntu2.7 [103 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.38-4ubuntu2.7 [2,326 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbinutils amd64 2.38-4ubuntu2.7 [662 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils amd64 2.38-4ubuntu2.7 [3,196 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-common amd64 2.38-4ubuntu2.7 [222 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapr1 amd64 1.7.0-8ubuntu0.22.04.2 [108 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libaprutil1 amd64 1.6.1-5ubuntu4.22.04.2 [92.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libserf-1-1 amd64 1.3.9-10ubuntu2 [50.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libutf8proc2 amd64 2.7.0-3 [73.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsvn1 amd64 1.14.1-3ubuntu0.22.04.1 [1,387 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxpm-dev amd64 1:3.5.12-1ubuntu0.22.04.2 [90.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 subversion amd64 1.14.1-3ubuntu0.22.04.1 [960 kB]\n",
            "Fetched 6,080 kB in 2s (2,757 kB/s)\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libctf0_2.38-4ubuntu2.7_amd64.deb ...\n",
            "Unpacking libctf0:amd64 (2.38-4ubuntu2.7) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../01-binutils-x86-64-linux-gnu_2.38-4ubuntu2.7_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.38-4ubuntu2.7) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../02-libbinutils_2.38-4ubuntu2.7_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.38-4ubuntu2.7) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../03-binutils_2.38-4ubuntu2.7_amd64.deb ...\n",
            "Unpacking binutils (2.38-4ubuntu2.7) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../04-binutils-common_2.38-4ubuntu2.7_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.38-4ubuntu2.7) over (2.38-4ubuntu2.6) ...\n",
            "Selecting previously unselected package libapr1:amd64.\n",
            "Preparing to unpack .../05-libapr1_1.7.0-8ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libapr1:amd64 (1.7.0-8ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaprutil1:amd64.\n",
            "Preparing to unpack .../06-libaprutil1_1.6.1-5ubuntu4.22.04.2_amd64.deb ...\n",
            "Unpacking libaprutil1:amd64 (1.6.1-5ubuntu4.22.04.2) ...\n",
            "Selecting previously unselected package libserf-1-1:amd64.\n",
            "Preparing to unpack .../07-libserf-1-1_1.3.9-10ubuntu2_amd64.deb ...\n",
            "Unpacking libserf-1-1:amd64 (1.3.9-10ubuntu2) ...\n",
            "Selecting previously unselected package libutf8proc2:amd64.\n",
            "Preparing to unpack .../08-libutf8proc2_2.7.0-3_amd64.deb ...\n",
            "Unpacking libutf8proc2:amd64 (2.7.0-3) ...\n",
            "Selecting previously unselected package libsvn1:amd64.\n",
            "Preparing to unpack .../09-libsvn1_1.14.1-3ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsvn1:amd64 (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libxpm-dev:amd64.\n",
            "Preparing to unpack .../10-libxpm-dev_1%3a3.5.12-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libxpm-dev:amd64 (1:3.5.12-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package subversion.\n",
            "Preparing to unpack .../11-subversion_1.14.1-3ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking subversion (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Setting up libutf8proc2:amd64 (2.7.0-3) ...\n",
            "Setting up binutils-common:amd64 (2.38-4ubuntu2.7) ...\n",
            "Setting up libapr1:amd64 (1.7.0-8ubuntu0.22.04.2) ...\n",
            "Setting up libxpm-dev:amd64 (1:3.5.12-1ubuntu0.22.04.2) ...\n",
            "Setting up libbinutils:amd64 (2.38-4ubuntu2.7) ...\n",
            "Setting up libaprutil1:amd64 (1.6.1-5ubuntu4.22.04.2) ...\n",
            "Setting up libctf0:amd64 (2.38-4ubuntu2.7) ...\n",
            "Setting up libserf-1-1:amd64 (1.3.9-10ubuntu2) ...\n",
            "Setting up libsvn1:amd64 (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.38-4ubuntu2.7) ...\n",
            "Setting up subversion (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Setting up binutils (2.38-4ubuntu2.7) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "--2025-03-18 09:49:35--  http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.82, 185.125.190.82, 185.125.190.81, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1318204 (1.3M) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb’\n",
            "\n",
            "libssl1.1_1.1.1f-1u 100%[===================>]   1.26M   833KB/s    in 1.5s    \n",
            "\n",
            "2025-03-18 09:49:37 (833 KB/s) - ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb’ saved [1318204/1318204]\n",
            "\n",
            "Selecting previously unselected package libssl1.1:amd64.\n",
            "(Reading database ... 125194 files and directories currently installed.)\n",
            "Preparing to unpack libssl1.1_1.1.1f-1ubuntu2_amd64.deb ...\n",
            "Unpacking libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\n",
            "Setting up libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download the pre-built ROOT tarball from GitHub Releases\n",
        "!wget -q --show-progress https://github.com/MohamedElashri/ROOT/releases/download/ubuntu/root_v6.30.04_Ubuntu_Python3.11.zip\n",
        "# Step 2: Extract the ROOT files\n",
        "!unzip -q root_v6.30.04_Ubuntu_Python3.11.zip\n",
        "\n",
        "# Step 3: Install missing system dependencies for ROOT\n",
        "!sudo ldconfig & apt-get install -y git dpkg-dev cmake g++ gcc binutils libx11-dev libxpm-dev libxft-dev libxext-dev tar gfortran subversion libpython3.11-dev\n",
        "\n",
        "# Step 4: Remove the tarball to free up space\n",
        "!rm -f root_v6.30.04_Ubuntu_Python3.11.zip\n",
        "\n",
        "# Step 5: Install Compatible libssl\n",
        "\n",
        "!wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "!rm -f libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/tmva_cuda_project/include/TMVA\n",
        "!mkdir -p /content/tmva_cuda_project/src\n",
        "!mkdir -p /content/tmva_cuda_project/test\n",
        "!mkdir -p /content/tmva_cuda_project/build"
      ],
      "metadata": {
        "id": "n-wJ9_nF2nHw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/include/TMVA/ROperator_Elu_CUDA.hxx\n",
        "#ifndef TMVA_SOFIE_ROPERATOR_ELU_CUDA\n",
        "#define TMVA_SOFIE_ROPERATOR_ELU_CUDA\n",
        "\n",
        "#include \"TMVA/RModel.hxx\"\n",
        "#include \"TMVA/ROperator.hxx\"\n",
        "#include \"TMVA/SOFIE_common.hxx\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "template <typename T>\n",
        "class ROperator_Elu_CUDA final : public ROperator\n",
        "{\n",
        "private:\n",
        "   /* Attributes */\n",
        "   float falpha = 1.0; // default value\n",
        "   std::string fNX;\n",
        "   std::string fNY;\n",
        "   std::vector<size_t> fShape;\n",
        "   std::string fType;\n",
        "\n",
        "public:\n",
        "   ROperator_Elu_CUDA() {}\n",
        "\n",
        "   ROperator_Elu_CUDA(float alpha, std::string nameX, std::string nameY):\n",
        "      falpha(alpha), fNX(UTILITY::Clean_name(nameX)), fNY(UTILITY::Clean_name(nameY))\n",
        "   {\n",
        "      fInputTensorNames = { fNX };\n",
        "      fOutputTensorNames = { fNY };\n",
        "\n",
        "      if (std::is_same<T, float>::value) {\n",
        "         fType = \"float\";\n",
        "      } else if (std::is_same<T, double>::value) {\n",
        "         fType = \"double\";\n",
        "      } else {\n",
        "         throw std::runtime_error(\"TMVA SOFIE Encountered unsupported type parsing a Elu CUDA operator\");\n",
        "      }\n",
        "   }\n",
        "\n",
        "   std::vector<ETensorType> TypeInference(std::vector<ETensorType> input) override {\n",
        "      return input;\n",
        "   }\n",
        "\n",
        "   std::vector<std::vector<size_t>> ShapeInference(std::vector<std::vector<size_t>> input) override {\n",
        "      auto ret = input; // suggest copy to compiler\n",
        "      return ret;\n",
        "   }\n",
        "\n",
        "   // Required ROperator interface methods\n",
        "   void Initialize(RModel& model) override;\n",
        "   std::string Generate(std::string OpName) override;\n",
        "};\n",
        "\n",
        "// Declare template specializations\n",
        "extern template class ROperator_Elu_CUDA<float>;\n",
        "extern template class ROperator_Elu_CUDA<double>;\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_ROPERATOR_ELU_CUDA"
      ],
      "metadata": {
        "id": "hjUHOHsc3BpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00380fa8-3d74-4692-fe07-669ff9bff11d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/include/TMVA/ROperator_Elu_CUDA.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/test/test_elu_cuda.cu\n",
        "#include \"TMVA/ROperator_Elu_CUDA.hxx\"\n",
        "#include \"TMVA/RModel.hxx\"\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <iomanip>\n",
        "#include <cmath>\n",
        "\n",
        "using namespace TMVA::Experimental::SOFIE;\n",
        "\n",
        "// Function to print tensor data\n",
        "template <typename T>\n",
        "void printTensor(const std::vector<T>& data, const std::vector<size_t>& shape) {\n",
        "    if (shape.size() == 1) {\n",
        "        for (size_t i = 0; i < std::min(data.size(), size_t(10)); i++) {\n",
        "            std::cout << std::fixed << std::setprecision(4) << data[i] << \" \";\n",
        "        }\n",
        "        if (data.size() > 10) std::cout << \"...\";\n",
        "        std::cout << std::endl;\n",
        "    } else if (shape.size() == 2) {\n",
        "        for (size_t i = 0; i < std::min(shape[0], size_t(5)); i++) {\n",
        "            for (size_t j = 0; j < std::min(shape[1], size_t(10)); j++) {\n",
        "                std::cout << std::fixed << std::setprecision(4) << data[i * shape[1] + j] << \" \";\n",
        "            }\n",
        "            if (shape[1] > 10) std::cout << \"...\";\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "        if (shape[0] > 5) std::cout << \"...\" << std::endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU implementation of ELU for comparison\n",
        "template <typename T>\n",
        "std::vector<T> cpuELU(const std::vector<T>& input, T alpha) {\n",
        "    std::vector<T> output(input.size());\n",
        "    for (size_t i = 0; i < input.size(); i++) {\n",
        "        T x = input[i];\n",
        "        output[i] = x >= 0 ? x : alpha * (std::exp(x) - 1);\n",
        "    }\n",
        "    return output;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"Testing TMVA SOFIE CUDA ELU Operator\" << std::endl;\n",
        "    std::cout << \"====================================\" << std::endl;\n",
        "\n",
        "    try {\n",
        "        // Create a model\n",
        "        RModel model(\"cuda_elu_test\", \"2025-03-14\");\n",
        "\n",
        "        // Create input tensor with range of values\n",
        "        std::vector<size_t> shape = {5, 3};\n",
        "        std::vector<float> input_data = {\n",
        "            // Values from -2.0 to 2.0 to show ELU behavior\n",
        "            -2.0f, -1.5f, -1.0f,\n",
        "            -0.5f, 0.0f, 0.5f,\n",
        "            1.0f, 1.5f, 2.0f,\n",
        "            -0.3f, -0.2f, -0.1f,\n",
        "            0.1f, 0.2f, 0.3f\n",
        "        };\n",
        "\n",
        "        // Add input tensor to model\n",
        "        model.AddInputTensorInfo(\"input\", ETensorType::FLOAT, shape);\n",
        "\n",
        "        // Initialize the model\n",
        "        model.Initialize();\n",
        "\n",
        "        // Test with different alpha values\n",
        "        float alpha_values[] = {0.1f, 1.0f, 2.0f};\n",
        "\n",
        "        for (float alpha : alpha_values) {\n",
        "            std::cout << \"\\n---- Testing with alpha = \" << alpha << \" ----\" << std::endl;\n",
        "\n",
        "            // Create ELU CUDA operator\n",
        "            ROperator_Elu_CUDA<float> eluOp(alpha, \"input\", \"output\");\n",
        "\n",
        "            // Initialize operator\n",
        "            eluOp.Initialize(model);\n",
        "\n",
        "            // Generate code\n",
        "            std::string generatedCode = eluOp.Generate(\"TestElu\");\n",
        "\n",
        "            // Print the generated code (excerpt)\n",
        "            std::cout << \"\\nGenerated CUDA code (excerpt):\" << std::endl;\n",
        "            std::cout << generatedCode.substr(0, 250) << \"...\\n\" << std::endl;\n",
        "\n",
        "            // Calculate expected output using CPU implementation\n",
        "            auto expected_output = cpuELU(input_data, alpha);\n",
        "\n",
        "            // Print input and expected output\n",
        "            std::cout << \"Input tensor:\" << std::endl;\n",
        "            printTensor(input_data, shape);\n",
        "\n",
        "            std::cout << \"\\nExpected output tensor (CPU ELU with alpha=\" << alpha << \"):\" << std::endl;\n",
        "            printTensor(expected_output, shape);\n",
        "\n",
        "            // Highlight specific values to demonstrate ELU behavior\n",
        "            std::cout << \"\\nELU behavior examples (alpha=\" << alpha << \"):\" << std::endl;\n",
        "            std::cout << \"For x = -1.0: ELU(x) = \" << (alpha * (std::exp(-1.0f) - 1.0f)) << std::endl;\n",
        "            std::cout << \"For x = 0.0: ELU(x) = \" << 0.0f << std::endl;\n",
        "            std::cout << \"For x = 1.0: ELU(x) = \" << 1.0f << std::endl;\n",
        "        }\n",
        "\n",
        "        std::cout << \"\\nELU CUDA operator test completed successfully!\" << std::endl;\n",
        "\n",
        "        return 0;\n",
        "    } catch (const std::exception& e) {\n",
        "        std::cerr << \"Error: \" << e.what() << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "385xCd8H444Y",
        "outputId": "9e0e720f-4dc2-47f9-b2c3-09f87dbb73ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/test/test_elu_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/CMakeLists.txt\n",
        "cmake_minimum_required(VERSION 3.10)\n",
        "project(TMVA_SOFIE_CUDA CUDA CXX)\n",
        "\n",
        "# Set C++ standard\n",
        "set(CMAKE_CXX_STANDARD 14)\n",
        "set(CMAKE_CUDA_STANDARD 14)\n",
        "set(CMAKE_CUDA_ARCHITECTURES 70)\n",
        "\n",
        "# Find CUDA\n",
        "find_package(CUDA REQUIRED)\n",
        "\n",
        "# Include directories\n",
        "include_directories(\n",
        "    ${CMAKE_CURRENT_SOURCE_DIR}/include\n",
        "    ${CUDA_INCLUDE_DIRS}\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Add ELU CUDA operator\n",
        "cuda_add_executable(test_elu_cuda\n",
        "    test/test_elu_cuda.cu\n",
        "    src/ROperator_Elu_CUDA.cu\n",
        ")\n",
        "\n",
        "# Link against CUDA libraries\n",
        "\n",
        "target_link_libraries(test_elu_cuda ${CUDA_LIBRARIES})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsr9dTV48ZR",
        "outputId": "71d6d6c4-6541-4c4b-e506-868fe23d840e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/CMakeLists.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile /content/tmva_cuda_project/include/TMVA/ROperator_Elu_CUDA.hxx\n",
        "#ifndef TMVA_SOFIE_ROPERATOR_ELU_CUDA\n",
        "#define TMVA_SOFIE_ROPERATOR_ELU_CUDA\n",
        "\n",
        "#include \"TMVA/ROperator.hxx\"\n",
        "#include \"TMVA/SOFIE_common.hxx\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "template <typename T>\n",
        "class ROperator_Elu_CUDA final : public ROperator\n",
        "{\n",
        "private:\n",
        "   /* Attributes */\n",
        "   float falpha = 1.0; // default value\n",
        "   std::string fNX;\n",
        "   std::string fNY;\n",
        "   std::vector<size_t> fShape;\n",
        "   std::string fType;\n",
        "\n",
        "public:\n",
        "   ROperator_Elu_CUDA() {}\n",
        "\n",
        "   ROperator_Elu_CUDA(float alpha, std::string nameX, std::string nameY):\n",
        "      falpha(alpha), fNX(UTILITY::Clean_name(nameX)), fNY(UTILITY::Clean_name(nameY))\n",
        "   {\n",
        "      fInputTensorNames = { fNX };\n",
        "      fOutputTensorNames = { fNY };\n",
        "\n",
        "      if (std::is_same<T, float>::value) {\n",
        "         fType = \"float\";\n",
        "      } else if (std::is_same<T, double>::value) {\n",
        "         fType = \"double\";\n",
        "      } else {\n",
        "         throw std::runtime_error(\"TMVA SOFIE Encountered unsupported type parsing a Elu CUDA operator\");\n",
        "      }\n",
        "   }\n",
        "\n",
        "   std::vector<ETensorType> TypeInference(std::vector<ETensorType> input) {\n",
        "      return input;\n",
        "   }\n",
        "\n",
        "   std::vector<std::vector<size_t>> ShapeInference(std::vector<std::vector<size_t>> input) {\n",
        "      auto ret = input; // suggest copy to compiler\n",
        "      return ret;\n",
        "   }\n",
        "\n",
        "   // Required ROperator interface methods\n",
        "   void Initialize(RModel& model) override;\n",
        "   std::string Generate(std::string OpName) override;\n",
        "};\n",
        "\n",
        "// Declare template specializations\n",
        "extern template class ROperator_Elu_CUDA<float>;\n",
        "extern template class ROperator_Elu_CUDA<double>;\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_ROPERATOR_ELU_CUDA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeZuBTNJ5FBD",
        "outputId": "e0610212-dcc5-4de4-af99-2a9e267c5d80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/tmva_cuda_project/include/TMVA/ROperator_Elu_CUDA.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile /content/tmva_cuda_project/src/ROperator_Elu_CUDA.cu\n",
        "#include \"TMVA/ROperator_Elu_CUDA.hxx\"\n",
        "#include \"TMVA/RModel.hxx\"  // Explicitly include RModel.hxx here\n",
        "#include <sstream>\n",
        "#include <cmath>\n",
        "#include <iomanip>\n",
        "#include <limits>\n",
        "\n",
        "// CUDA kernel for ELU with float\n",
        "__global__ void eluKernelFloat(const float* input, float* output, size_t size, float alpha) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        float x = input[idx];\n",
        "        output[idx] = x >= 0.0f ? x : alpha * (expf(x) - 1.0f);\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for ELU with double precision\n",
        "__global__ void eluKernelDouble(const double* input, double* output, size_t size, double alpha) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        double x = input[idx];\n",
        "        output[idx] = x >= 0.0 ? x : alpha * (exp(x) - 1.0);\n",
        "    }\n",
        "}\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "template <typename T>\n",
        "void ROperator_Elu_CUDA<T>::Initialize(RModel& model)\n",
        "{\n",
        "    if (model.CheckIfTensorAlreadyExist(fNX) == false) {\n",
        "        throw std::runtime_error(\"TMVA SOFIE Elu CUDA Op Input Tensor \" + fNX + \" is not found in model\");\n",
        "    }\n",
        "\n",
        "    // Get shape from the model\n",
        "    fShape = model.GetTensorShape(fNX);\n",
        "\n",
        "    // Add output tensor to the model with same type and shape as input\n",
        "    model.AddIntermediateTensor(fNY, model.GetTensorType(fNX), fShape);\n",
        "\n",
        "    if (model.Verbose()) {\n",
        "        std::cout << \"ELU CUDA: \" << fNX << \" -> \" << fNY << \" (alpha=\" << falpha << \")\" << std::endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "std::string ROperator_Elu_CUDA<T>::Generate(std::string OpName)\n",
        "{\n",
        "    OpName = \"op_\" + OpName;\n",
        "    if (fShape.empty()) {\n",
        "        throw std::runtime_error(\"TMVA SOFIE Operator Elu CUDA called to Generate without being initialized first\");\n",
        "    }\n",
        "\n",
        "    std::stringstream out;\n",
        "    size_t length = ConvertShapeToLength(fShape);\n",
        "\n",
        "    // Define alpha parameter with full precision\n",
        "    out << SP << fType << \" \" << OpName << \"_alpha = \"\n",
        "        << std::setprecision(std::numeric_limits<float>::max_digits10) << falpha << \";\\n\";\n",
        "\n",
        "    // Begin CUDA implementation\n",
        "    out << \"\\n//------ ELU CUDA\\n\";\n",
        "\n",
        "    // 1. Define the kernel\n",
        "    out << SP << \"// CUDA kernel for ELU operation\\n\";\n",
        "    out << SP << \"__global__ void \" << OpName << \"_elu_kernel(const \" << fType << \"* input, \"\n",
        "        << fType << \"* output, size_t size, \" << fType << \" alpha) {\\n\";\n",
        "    out << SP << SP << \"int idx = blockIdx.x * blockDim.x + threadIdx.x;\\n\";\n",
        "    out << SP << SP << \"if (idx < size) {\\n\";\n",
        "    out << SP << SP << SP << fType << \" x = input[idx];\\n\";\n",
        "\n",
        "    // Type-specific implementation\n",
        "    if (std::is_same<T, float>::value) {\n",
        "        out << SP << SP << SP << \"output[idx] = x >= 0.0f ? x : alpha * (expf(x) - 1.0f);\\n\";\n",
        "    } else if (std::is_same<T, double>::value) {\n",
        "        out << SP << SP << SP << \"output[idx] = x >= 0.0 ? x : alpha * (exp(x) - 1.0);\\n\";\n",
        "    }\n",
        "\n",
        "    out << SP << SP << \"}\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    // 2. Execution code block\n",
        "    out << SP << \"// Calculate execution configuration\\n\";\n",
        "    out << SP << \"size_t size = \" << length << \";\\n\";\n",
        "    out << SP << \"int blockSize = 256;\\n\";\n",
        "    out << SP << \"int numBlocks = (size + blockSize - 1) / blockSize;\\n\\n\";\n",
        "\n",
        "    // GPU Memory allocation\n",
        "    out << SP << \"// Allocate device memory\\n\";\n",
        "    out << SP << fType << \"* d_input = nullptr;\\n\";\n",
        "    out << SP << fType << \"* d_output = nullptr;\\n\";\n",
        "    out << SP << \"cudaError_t cudaStatus;\\n\\n\";\n",
        "\n",
        "    // Error handling and memory management\n",
        "    out << SP << \"// CUDA memory allocation\\n\";\n",
        "    out << SP << \"cudaStatus = cudaMalloc(&d_input, size * sizeof(\" << fType << \"));\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"cudaMalloc failed for input: \\\" << cudaGetErrorString(cudaStatus) << std::endl;\\n\";\n",
        "    out << SP << SP << \"goto \" << OpName << \"_cleanup;\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    out << SP << \"cudaStatus = cudaMalloc(&d_output, size * sizeof(\" << fType << \"));\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"cudaMalloc failed for output: \\\" << cudaGetErrorString(cudaStatus) << std::endl;\\n\";\n",
        "    out << SP << SP << \"goto \" << OpName << \"_cleanup;\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    // Copy input to device\n",
        "    out << SP << \"// Copy input to device\\n\";\n",
        "    out << SP << \"cudaStatus = cudaMemcpy(d_input, tensor_\" << fNX << \", size * sizeof(\" << fType << \"), cudaMemcpyHostToDevice);\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"cudaMemcpy to device failed: \\\" << cudaGetErrorString(cudaStatus) << std::endl;\\n\";\n",
        "    out << SP << SP << \"goto \" << OpName << \"_cleanup;\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    // Launch kernel\n",
        "    out << SP << \"// Launch ELU kernel\\n\";\n",
        "    out << SP << OpName << \"_elu_kernel<<<numBlocks, blockSize>>>(d_input, d_output, size, \" << OpName << \"_alpha);\\n\\n\";\n",
        "\n",
        "    // Check for kernel errors\n",
        "    out << SP << \"// Check for kernel errors\\n\";\n",
        "    out << SP << \"cudaStatus = cudaGetLastError();\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"CUDA kernel launch failed: \\\" << cudaGetErrorString(cudaStatus) << std::endl;\\n\";\n",
        "    out << SP << SP << \"goto \" << OpName << \"_cleanup;\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    // Synchronize\n",
        "    out << SP << \"// Wait for kernel completion\\n\";\n",
        "    out << SP << \"cudaStatus = cudaDeviceSynchronize();\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"cudaDeviceSynchronize failed: \\\" << cudaGetErrorString(cudaStatus) << std::endl;\\n\";\n",
        "    out << SP << SP << \"goto \" << OpName << \"_cleanup;\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    // Copy result back to host\n",
        "    out << SP << \"// Copy result back to host\\n\";\n",
        "    out << SP << \"cudaStatus = cudaMemcpy(tensor_\" << fNY << \", d_output, size * sizeof(\" << fType << \"), cudaMemcpyDeviceToHost);\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"cudaMemcpy to host failed: \\\" << cudaGetErrorString(cudaStatus) << std::endl;\\n\";\n",
        "    out << SP << SP << \"goto \" << OpName << \"_cleanup;\\n\";\n",
        "    out << SP << \"}\\n\\n\";\n",
        "\n",
        "    // Cleanup section\n",
        "    out << SP << OpName << \"_cleanup:\\n\";\n",
        "    out << SP << \"// Clean up device memory\\n\";\n",
        "    out << SP << \"if (d_input) cudaFree(d_input);\\n\";\n",
        "    out << SP << \"if (d_output) cudaFree(d_output);\\n\\n\";\n",
        "\n",
        "    // CPU fallback if CUDA fails\n",
        "    out << SP << \"// CPU fallback if CUDA execution failed\\n\";\n",
        "    out << SP << \"if (cudaStatus != cudaSuccess) {\\n\";\n",
        "    out << SP << SP << \"std::cerr << \\\"Using CPU fallback for ELU operation\\\" << std::endl;\\n\";\n",
        "    out << SP << SP << \"for (int id = 0; id < \" << length << \"; id++) {\\n\";\n",
        "    out << SP << SP << SP << \"tensor_\" << fNY << \"[id] = ((tensor_\" << fNX << \"[id] >= 0) ? tensor_\" << fNX;\n",
        "    out << \"[id] : \" << OpName << \"_alpha * std::exp(tensor_\" << fNX << \"[id]) - 1);\\n\";\n",
        "    out << SP << SP << \"}\\n\";\n",
        "    out << SP << \"}\\n\";\n",
        "\n",
        "    return out.str();\n",
        "}\n",
        "\n",
        "// Explicit template instantiations\n",
        "template class ROperator_Elu_CUDA<float>;\n",
        "template class ROperator_Elu_CUDA<double>;\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv1iL42K6bLG",
        "outputId": "7258a9af-8cd0-45d6-cec0-32b9e93002ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/src/ROperator_Elu_CUDA.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/test/test_elu_cuda.cu\n",
        "#include \"TMVA/ROperator_Elu_CUDA.hxx\"\n",
        "#include \"TMVA/RModel.hxx\"\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <iomanip>\n",
        "#include <cmath>\n",
        "\n",
        "using namespace TMVA::Experimental::SOFIE;\n",
        "\n",
        "// Function to print tensor data\n",
        "template <typename T>\n",
        "void printTensor(const std::vector<T>& data, const std::vector<size_t>& shape) {\n",
        "    if (shape.size() == 1) {\n",
        "        for (size_t i = 0; i < std::min(data.size(), size_t(10)); i++) {\n",
        "            std::cout << std::fixed << std::setprecision(4) << data[i] << \" \";\n",
        "        }\n",
        "        if (data.size() > 10) std::cout << \"...\";\n",
        "        std::cout << std::endl;\n",
        "    } else if (shape.size() == 2) {\n",
        "        for (size_t i = 0; i < std::min(shape[0], size_t(5)); i++) {\n",
        "            for (size_t j = 0; j < std::min(shape[1], size_t(10)); j++) {\n",
        "                std::cout << std::fixed << std::setprecision(4) << data[i * shape[1] + j] << \" \";\n",
        "            }\n",
        "            if (shape[1] > 10) std::cout << \"...\";\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "        if (shape[0] > 5) std::cout << \"...\" << std::endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU implementation of ELU for comparison\n",
        "template <typename T>\n",
        "std::vector<T> cpuELU(const std::vector<T>& input, T alpha) {\n",
        "    std::vector<T> output(input.size());\n",
        "    for (size_t i = 0; i < input.size(); i++) {\n",
        "        T x = input[i];\n",
        "        output[i] = x >= 0 ? x : alpha * (std::exp(x) - 1);\n",
        "    }\n",
        "    return output;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"Testing TMVA SOFIE CUDA ELU Operator\" << std::endl;\n",
        "    std::cout << \"====================================\" << std::endl;\n",
        "\n",
        "    try {\n",
        "        // Create a model\n",
        "        RModel model(\"cuda_elu_test\", \"2025-03-14\");\n",
        "\n",
        "        // Create input tensor with range of values\n",
        "        std::vector<size_t> shape = {5, 3};\n",
        "        std::vector<float> input_data = {\n",
        "            // Values from -2.0 to 2.0 to show ELU behavior\n",
        "            -2.0f, -1.5f, -1.0f,\n",
        "            -0.5f, 0.0f, 0.5f,\n",
        "            1.0f, 1.5f, 2.0f,\n",
        "            -0.3f, -0.2f, -0.1f,\n",
        "            0.1f, 0.2f, 0.3f\n",
        "        };\n",
        "\n",
        "        // Add input tensor to model\n",
        "        model.AddInputTensorInfo(\"input\", ETensorType::FLOAT, shape);\n",
        "\n",
        "        // Initialize the model\n",
        "        model.Initialize();\n",
        "\n",
        "        // Test with different alpha values\n",
        "        float alpha_values[] = {0.1f, 1.0f, 2.0f};\n",
        "\n",
        "        for (float alpha : alpha_values) {\n",
        "            std::cout << \"\\n---- Testing with alpha = \" << alpha << \" ----\" << std::endl;\n",
        "\n",
        "            // Create ELU CUDA operator\n",
        "            ROperator_Elu_CUDA<float> eluOp(alpha, \"input\", \"output\");\n",
        "\n",
        "            // Initialize operator\n",
        "            eluOp.Initialize(model);\n",
        "\n",
        "            // Generate code\n",
        "            std::string generatedCode = eluOp.Generate(\"TestElu\");\n",
        "\n",
        "            // Print the generated code (excerpt)\n",
        "            std::cout << \"\\nGenerated CUDA code (excerpt):\" << std::endl;\n",
        "            std::cout << generatedCode.substr(0, 250) << \"...\\n\" << std::endl;\n",
        "\n",
        "            // Calculate expected output using CPU implementation\n",
        "            auto expected_output = cpuELU(input_data, alpha);\n",
        "\n",
        "            // Print input and expected output\n",
        "            std::cout << \"Input tensor:\" << std::endl;\n",
        "            printTensor(input_data, shape);\n",
        "\n",
        "            std::cout << \"\\nExpected output tensor (CPU ELU with alpha=\" << alpha << \"):\" << std::endl;\n",
        "            printTensor(expected_output, shape);\n",
        "\n",
        "            // Highlight specific values to demonstrate ELU behavior\n",
        "            std::cout << \"\\nELU behavior examples (alpha=\" << alpha << \"):\" << std::endl;\n",
        "            std::cout << \"For x = -1.0: ELU(x) = \" << (alpha * (std::exp(-1.0f) - 1.0f)) << std::endl;\n",
        "            std::cout << \"For x = 0.0: ELU(x) = \" << 0.0f << std::endl;\n",
        "            std::cout << \"For x = 1.0: ELU(x) = \" << 1.0f << std::endl;\n",
        "        }\n",
        "\n",
        "        std::cout << \"\\nELU CUDA operator test completed successfully!\" << std::endl;\n",
        "\n",
        "        return 0;\n",
        "    } catch (const std::exception& e) {\n",
        "        std::cerr << \"Error: \" << e.what() << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrqxOO337WLW",
        "outputId": "711a4e98-6fcf-4981-95cc-ad3f143f0b10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/tmva_cuda_project/test/test_elu_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/include/TMVA/ROperator.hxx\n",
        "#ifndef TMVA_SOFIE_ROPERATOR\n",
        "#define TMVA_SOFIE_ROPERATOR\n",
        "\n",
        "#include \"TMVA/SOFIE_common.hxx\"\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <memory>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "// Forward declaration\n",
        "class RModel;\n",
        "\n",
        "// Base class for all operators\n",
        "class ROperator {\n",
        "public:\n",
        "    virtual ~ROperator() = default;\n",
        "\n",
        "    // Core required methods\n",
        "    virtual std::vector<std::vector<size_t>> ShapeInference(std::vector<std::vector<size_t>> input) = 0;\n",
        "    virtual std::vector<ETensorType> TypeInference(std::vector<ETensorType> input) = 0;\n",
        "    virtual void Initialize(RModel& model) = 0;\n",
        "    virtual std::string Generate(std::string OpName) = 0;\n",
        "\n",
        "    // Optional session-related methods (can be empty in mock implementation)\n",
        "    virtual std::string GenerateInitCode() { return \"\"; }\n",
        "    virtual std::string GenerateDeclCode() { return \"\"; }\n",
        "    virtual std::string GenerateSessionMembersCode(std::string /*opName*/) { return \"\"; }\n",
        "    virtual std::string Header() { return \"\"; }\n",
        "    virtual std::vector<std::string> GetBlasRoutines() { return {}; }\n",
        "    virtual std::vector<std::string> GetStdLibs() { return {}; }\n",
        "\n",
        "    // Common members\n",
        "    std::vector<std::string> fInputTensorNames;\n",
        "    std::vector<std::string> fOutputTensorNames;\n",
        "\n",
        "protected:\n",
        "    const std::string SP = \"   \"; // Space for indentation\n",
        "    bool fUseSession = false;     // Flag for session usage\n",
        "    bool fIsOutputConstant = false; // Flag for constant output tensors\n",
        "};\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_ROPERATOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuLwRtSv72tX",
        "outputId": "a5b70fe7-c8d2-4e74-f1ec-8ad19a1bf389"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/include/TMVA/ROperator.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/include/TMVA/RModel.hxx\n",
        "#ifndef TMVA_SOFIE_RMODEL\n",
        "#define TMVA_SOFIE_RMODEL\n",
        "\n",
        "#include \"TMVA/SOFIE_common.hxx\"\n",
        "#include \"TMVA/ROperator.hxx\"\n",
        "#include <unordered_map>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <memory>\n",
        "#include <map>\n",
        "#include <algorithm>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "// Options enum for code generation\n",
        "enum class Options {\n",
        "    kDefault = 0,\n",
        "    kNoSession = 1\n",
        "};\n",
        "\n",
        "// Mock RModel class that includes more official-like interfaces\n",
        "class RModel {\n",
        "private:\n",
        "    std::string fName;\n",
        "    std::string fParsedDateTime;\n",
        "    bool fIsInitialized = false;\n",
        "    int fVerbose = 1;\n",
        "    bool fUseSession = false;\n",
        "\n",
        "    // Tensor storage\n",
        "    std::unordered_map<std::string, InputTensorInfo> fInputTensorInfos;\n",
        "    std::unordered_map<std::string, TensorInfo> fReadyInputTensorInfos;\n",
        "    std::unordered_map<std::string, InitializedTensor> fInitializedTensors;\n",
        "    std::unordered_map<std::string, TensorInfo> fIntermediateTensorInfos;\n",
        "    std::unordered_map<std::string, DynamicTensorInfo> fDynamicTensorInfos;\n",
        "    std::vector<std::string> fOutputTensorNames;\n",
        "    std::vector<std::string> fInputTensorNames;\n",
        "\n",
        "    std::vector<std::unique_ptr<ROperator>> fOperators;\n",
        "\n",
        "public:\n",
        "    RModel() = default;\n",
        "    RModel(std::string name, std::string parsedtime) : fName(name), fParsedDateTime(parsedtime) {}\n",
        "\n",
        "    int Verbose() const { return fVerbose; }\n",
        "\n",
        "    const std::vector<size_t>& GetTensorShape(const std::string& name) {\n",
        "        auto it = fReadyInputTensorInfos.find(name);\n",
        "        if (it != fReadyInputTensorInfos.end()) {\n",
        "            return it->second.shape;\n",
        "        }\n",
        "        auto it2 = fIntermediateTensorInfos.find(name);\n",
        "        if (it2 != fIntermediateTensorInfos.end()) {\n",
        "            return it2->second.shape;\n",
        "        }\n",
        "        auto it3 = fInitializedTensors.find(name);\n",
        "        if (it3 != fInitializedTensors.end()) {\n",
        "            return it3->second.shape();\n",
        "        }\n",
        "        throw std::runtime_error(\"Tensor not found: \" + name);\n",
        "    }\n",
        "\n",
        "    const ETensorType& GetTensorType(const std::string& name) {\n",
        "        auto it = fReadyInputTensorInfos.find(name);\n",
        "        if (it != fReadyInputTensorInfos.end()) {\n",
        "            return it->second.type;\n",
        "        }\n",
        "        auto it2 = fIntermediateTensorInfos.find(name);\n",
        "        if (it2 != fIntermediateTensorInfos.end()) {\n",
        "            return it2->second.type;\n",
        "        }\n",
        "        auto it3 = fInitializedTensors.find(name);\n",
        "        if (it3 != fInitializedTensors.end()) {\n",
        "            return it3->second.type();\n",
        "        }\n",
        "        throw std::runtime_error(\"Tensor type not found: \" + name);\n",
        "    }\n",
        "\n",
        "    bool CheckIfTensorAlreadyExist(const std::string& name) {\n",
        "        return (fReadyInputTensorInfos.find(name) != fReadyInputTensorInfos.end()) ||\n",
        "               (fIntermediateTensorInfos.find(name) != fIntermediateTensorInfos.end()) ||\n",
        "               (fInitializedTensors.find(name) != fInitializedTensors.end()) ||\n",
        "               (fInputTensorInfos.find(name) != fInputTensorInfos.end());\n",
        "    }\n",
        "\n",
        "    // Add input tensor info\n",
        "    void AddInputTensorInfo(const std::string& name, ETensorType type, const std::vector<size_t>& shape) {\n",
        "        TensorInfo info;\n",
        "        info.type = type;\n",
        "        info.shape = shape;\n",
        "        fReadyInputTensorInfos[name] = info;\n",
        "\n",
        "        // Also add to input tensor names if not already there\n",
        "        if (std::find(fInputTensorNames.begin(), fInputTensorNames.end(), name) == fInputTensorNames.end()) {\n",
        "            fInputTensorNames.push_back(name);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Add input tensor with dynamic shape\n",
        "    void AddInputTensorInfo(const std::string& name, ETensorType type, const std::vector<Dim>& shape) {\n",
        "        InputTensorInfo info;\n",
        "        info.type = type;\n",
        "        info.shape = shape;\n",
        "        fInputTensorInfos[name] = info;\n",
        "\n",
        "        // Also add to input tensor names if not already there\n",
        "        if (std::find(fInputTensorNames.begin(), fInputTensorNames.end(), name) == fInputTensorNames.end()) {\n",
        "            fInputTensorNames.push_back(name);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Add intermediate tensor\n",
        "    void AddIntermediateTensor(const std::string& name, ETensorType type, const std::vector<size_t>& shape) {\n",
        "        TensorInfo info;\n",
        "        info.type = type;\n",
        "        info.shape = shape;\n",
        "        fIntermediateTensorInfos[name] = info;\n",
        "    }\n",
        "\n",
        "    // Add output tensor names\n",
        "    void AddOutputTensorNameList(const std::vector<std::string>& names) {\n",
        "        fOutputTensorNames = names;\n",
        "    }\n",
        "\n",
        "    // Add operator to model\n",
        "    void AddOperator(std::unique_ptr<ROperator> op) {\n",
        "        op->Initialize(*this);\n",
        "        fOperators.push_back(std::move(op));\n",
        "    }\n",
        "\n",
        "    // Initialize model\n",
        "    void Initialize(int batchSize = -1) {\n",
        "        fIsInitialized = true;\n",
        "        if (Verbose()) {\n",
        "            std::cout << \"Model initialized with batch size: \" <<\n",
        "                (batchSize == -1 ? \"default\" : std::to_string(batchSize)) << std::endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Code generation (simplified placeholder)\n",
        "    void Generate(Options options = Options::kDefault, int batchSize = -1) {\n",
        "        if (!fIsInitialized) {\n",
        "            Initialize(batchSize);\n",
        "        }\n",
        "\n",
        "        // Placeholder for actual generation logic\n",
        "        if (Verbose()) {\n",
        "            std::cout << \"Generating code with options: \" <<\n",
        "                static_cast<int>(options) << \" and batch size: \" <<\n",
        "                (batchSize == -1 ? \"default\" : std::to_string(batchSize)) << std::endl;\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_RMODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_tcpqcL76qS",
        "outputId": "1c301114-5b96-4ef0-bf05-82423b904fde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/include/TMVA/RModel.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/include/TMVA/ROperator.hxx\n",
        "#ifndef TMVA_SOFIE_ROPERATOR\n",
        "#define TMVA_SOFIE_ROPERATOR\n",
        "\n",
        "#include \"TMVA/SOFIE_common.hxx\"\n",
        "#include <string>\n",
        "#include <vector>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "// Forward declaration\n",
        "class RModel;\n",
        "\n",
        "// Base class for all operators\n",
        "class ROperator {\n",
        "public:\n",
        "    virtual ~ROperator() = default;\n",
        "    virtual void Initialize(RModel& model) = 0;\n",
        "    virtual std::string Generate(std::string OpName) = 0;\n",
        "\n",
        "    // Common members\n",
        "    std::vector<std::string> fInputTensorNames;\n",
        "    std::vector<std::string> fOutputTensorNames;\n",
        "};\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_ROPERATOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ2N7-ad8BKl",
        "outputId": "2a1c256a-6b58-4c48-f20f-0f0067bc98c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/tmva_cuda_project/include/TMVA/ROperator.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/include/TMVA/SOFIE_common.hxx\n",
        "#ifndef TMVA_SOFIE_COMMON\n",
        "#define TMVA_SOFIE_COMMON\n",
        "\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <memory>\n",
        "#include <stdexcept>\n",
        "#include <iostream>\n",
        "#include <unordered_map>\n",
        "#include <functional>\n",
        "#include <algorithm>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "// Basic tensor type enum (matching official implementation)\n",
        "enum class ETensorType {\n",
        "    UNDEFINED = 0, FLOAT = 1, UNINT8 = 2, INT8 = 3, UINT16 = 4, INT16 = 5,\n",
        "    INT32 = 6, INT64 = 7, STRING = 8, BOOL = 9, FLOAT16 = 10, DOUBLE = 11,\n",
        "    UINT32 = 12, UINT64 = 13, COMPLEX64 = 14, COMPLEX28 = 15, BFLOAT16 = 16\n",
        "};\n",
        "\n",
        "// Dimension structure for dynamic shapes\n",
        "struct Dim {\n",
        "    bool isParam = false;\n",
        "    size_t dim = 0;\n",
        "    std::string param;\n",
        "\n",
        "    // Constructors\n",
        "    Dim() {}\n",
        "    Dim(const std::string& p, size_t d = 0) : isParam(true), dim(d), param(p) {}\n",
        "    Dim(size_t d) : dim(d) {}\n",
        "\n",
        "    std::string GetVal() const {\n",
        "        return (isParam) ? param : std::to_string(dim);\n",
        "    }\n",
        "};\n",
        "\n",
        "struct InputTensorInfo {\n",
        "    ETensorType type;\n",
        "    std::vector<Dim> shape;\n",
        "};\n",
        "\n",
        "struct TensorInfo {\n",
        "    ETensorType type;\n",
        "    std::vector<size_t> shape;\n",
        "};\n",
        "\n",
        "struct DynamicTensorInfo {\n",
        "    ETensorType type;\n",
        "    std::vector<Dim> shape;\n",
        "};\n",
        "\n",
        "// Helper functions - add inline to prevent multiple definition errors\n",
        "inline size_t ConvertShapeToLength(const std::vector<size_t>& shape) {\n",
        "    size_t length = 1;\n",
        "    for (auto& dim : shape) {\n",
        "        length *= dim;\n",
        "    }\n",
        "    return length;\n",
        "}\n",
        "\n",
        "inline std::string ConvertShapeToString(std::vector<size_t> shape) {\n",
        "    std::string result = \"{\";\n",
        "    for (size_t i = 0; i < shape.size(); i++) {\n",
        "        result += std::to_string(shape[i]);\n",
        "        if (i < shape.size() - 1) result += \", \";\n",
        "    }\n",
        "    result += \"}\";\n",
        "    return result;\n",
        "}\n",
        "\n",
        "// Get string representation of type\n",
        "template<typename T>\n",
        "inline std::string GetTensorTypeName() {\n",
        "    if (std::is_same<T, float>::value) return \"float\";\n",
        "    if (std::is_same<T, double>::value) return \"double\";\n",
        "    if (std::is_same<T, int64_t>::value) return \"int64_t\";\n",
        "    if (std::is_same<T, int32_t>::value) return \"int32_t\";\n",
        "    if (std::is_same<T, bool>::value) return \"bool\";\n",
        "    return \"unknown\";\n",
        "}\n",
        "\n",
        "// Get ETensorType from C++ type\n",
        "template<typename T>\n",
        "ETensorType GetTemplatedType(T) {\n",
        "    if (std::is_same<T, float>::value) return ETensorType::FLOAT;\n",
        "    if (std::is_same<T, double>::value) return ETensorType::DOUBLE;\n",
        "    if (std::is_same<T, int64_t>::value) return ETensorType::INT64;\n",
        "    if (std::is_same<T, int32_t>::value) return ETensorType::INT32;\n",
        "    if (std::is_same<T, bool>::value) return ETensorType::BOOL;\n",
        "    throw std::runtime_error(\"Unsupported type in GetTemplatedType\");\n",
        "}\n",
        "\n",
        "// Simple initialized tensor class - simplified version of the official one\n",
        "class InitializedTensor {\n",
        "public:\n",
        "    InitializedTensor() = default;\n",
        "    InitializedTensor(ETensorType type, const std::vector<size_t>& shape,\n",
        "                     std::shared_ptr<void> data, bool constant = false)\n",
        "        : fConstant(constant), fType(type), fShape(shape), fData(data) {}\n",
        "\n",
        "    ETensorType const &type() const { return fType; }\n",
        "    std::vector<std::size_t> const &shape() const { return fShape; }\n",
        "    std::shared_ptr<void> const &sharedptr() const { return fData; }\n",
        "\n",
        "    // Additional flags to match official behavior\n",
        "    bool IsConstantTensor() const { return fConstant; }\n",
        "    bool IsWeightTensor() const { return !fConstant && !fIsNotWritable; }\n",
        "    void SetNotWritable() { fIsNotWritable = true; }\n",
        "\n",
        "    template <class T = void>\n",
        "    T const *data() const {\n",
        "        return static_cast<T const *>(fData.get());\n",
        "    }\n",
        "\n",
        "private:\n",
        "    bool fConstant = false;      // Flag for constant tensors\n",
        "    bool fIsNotWritable = false; // Flag for not writable tensors\n",
        "    ETensorType fType;\n",
        "    std::vector<size_t> fShape;\n",
        "    std::shared_ptr<void> fData;\n",
        "};\n",
        "\n",
        "// Utility namespace\n",
        "namespace UTILITY {\n",
        "    inline std::string Clean_name(const std::string& name) {\n",
        "        return name; // Simplified for testing\n",
        "    }\n",
        "\n",
        "    // Check if two shapes are equal\n",
        "    inline bool AreSameShape(const std::vector<size_t>& a, const std::vector<size_t>& b) {\n",
        "        if (a.size() != b.size()) return false;\n",
        "        for (size_t i = 0; i < a.size(); i++) {\n",
        "            if (a[i] != b[i]) return false;\n",
        "        }\n",
        "        return true;\n",
        "    }\n",
        "}\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_COMMON"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rqv9-yx9hx1",
        "outputId": "2deff775-9544-44b8-d120-1c14d6eed2ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/tmva_cuda_project/include/TMVA/SOFIE_common.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/tmva_cuda_project/include/TMVA/RModel.hxx\n",
        "#ifndef TMVA_SOFIE_RMODEL\n",
        "#define TMVA_SOFIE_RMODEL\n",
        "\n",
        "#include \"TMVA/SOFIE_common.hxx\"\n",
        "#include <unordered_map>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <memory>\n",
        "#include <map>\n",
        "#include <algorithm>\n",
        "\n",
        "namespace TMVA {\n",
        "namespace Experimental {\n",
        "namespace SOFIE {\n",
        "\n",
        "// Forward declaration\n",
        "class ROperator;\n",
        "\n",
        "// Mock RModel class for our implementation\n",
        "class RModel {\n",
        "private:\n",
        "    std::string fName;\n",
        "    std::string fParsedDateTime;\n",
        "    bool fIsInitialized = false;\n",
        "    int fVerbose = 1;\n",
        "\n",
        "    // Tensor storage\n",
        "    std::unordered_map<std::string, ETensorType> fTensorTypes;\n",
        "    std::unordered_map<std::string, std::vector<size_t>> fTensorShapes;\n",
        "    std::vector<std::string> fOutputTensorNames;\n",
        "    std::vector<std::string> fInputTensorNames;\n",
        "\n",
        "public:\n",
        "    RModel() = default;\n",
        "    RModel(std::string name, std::string parsedtime) : fName(name), fParsedDateTime(parsedtime) {}\n",
        "\n",
        "    int Verbose() const { return fVerbose; }\n",
        "\n",
        "    const std::vector<size_t>& GetTensorShape(const std::string& name) {\n",
        "        auto it = fTensorShapes.find(name);\n",
        "        if (it != fTensorShapes.end()) {\n",
        "            return it->second;\n",
        "        }\n",
        "        throw std::runtime_error(\"Tensor not found: \" + name);\n",
        "    }\n",
        "\n",
        "    const ETensorType& GetTensorType(const std::string& name) {\n",
        "        auto it = fTensorTypes.find(name);\n",
        "        if (it != fTensorTypes.end()) {\n",
        "            return it->second;\n",
        "        }\n",
        "        throw std::runtime_error(\"Tensor type not found: \" + name);\n",
        "    }\n",
        "\n",
        "    bool CheckIfTensorAlreadyExist(const std::string& name) const {\n",
        "        return fTensorShapes.find(name) != fTensorShapes.end();\n",
        "    }\n",
        "\n",
        "    // Add input tensor info\n",
        "    void AddInputTensorInfo(const std::string& name, ETensorType type, const std::vector<size_t>& shape) {\n",
        "        fTensorTypes[name] = type;\n",
        "        fTensorShapes[name] = shape;\n",
        "\n",
        "        // Also add to input tensor names if not already there\n",
        "        if (std::find(fInputTensorNames.begin(), fInputTensorNames.end(), name) == fInputTensorNames.end()) {\n",
        "            fInputTensorNames.push_back(name);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Add intermediate tensor\n",
        "    void AddIntermediateTensor(const std::string& name, ETensorType type, const std::vector<size_t>& shape) {\n",
        "        fTensorTypes[name] = type;\n",
        "        fTensorShapes[name] = shape;\n",
        "    }\n",
        "\n",
        "    // Add output tensor names\n",
        "    void AddOutputTensorNameList(const std::vector<std::string>& names) {\n",
        "        fOutputTensorNames = names;\n",
        "    }\n",
        "\n",
        "    // Initialize model (simplified for mock)\n",
        "    void Initialize(int batchSize = -1) {\n",
        "        fIsInitialized = true;\n",
        "\n",
        "        if (Verbose()) {\n",
        "            std::cout << \"Model initialized with batch size: \" <<\n",
        "                (batchSize == -1 ? \"default\" : std::to_string(batchSize)) << std::endl;\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "}}} // namespace TMVA::Experimental::SOFIE\n",
        "\n",
        "#endif // TMVA_SOFIE_RMODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW3XGpKo9kIw",
        "outputId": "5b29f866-b5b7-41c6-d14f-1197d915b167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/tmva_cuda_project/include/TMVA/RModel.hxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/tmva_cuda_project && cmake -B build && cmake --build build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0ttI6Dh9mtz",
        "outputId": "53573241-c9eb-4b4c-818e-debd646c36ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:10 (find_package):\n",
            "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
            "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
            "  set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Found CUDA: /usr/local/cuda (found version \"12.5\")\n",
            "-- Configuring done (4.2s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/tmva_cuda_project/build\n",
            "[ 33%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/test_elu_cuda.dir/test/test_elu_cuda_generated_test_elu_cuda.cu.o\u001b[0m\n",
            "[ 66%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/test_elu_cuda.dir/src/test_elu_cuda_generated_ROperator_Elu_CUDA.cu.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable test_elu_cuda\u001b[0m\n",
            "[100%] Built target test_elu_cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/tmva_cuda_project/build && ./test_elu_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqtQCNEX9o74",
        "outputId": "9c939a94-5827-49d1-8e6c-bba5eaaccbb5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing TMVA SOFIE CUDA ELU Operator\n",
            "====================================\n",
            "Model initialized with batch size: default\n",
            "\n",
            "---- Testing with alpha = 0.1 ----\n",
            "ELU CUDA: input -> output (alpha=0.1)\n",
            "\n",
            "Generated CUDA code (excerpt):\n",
            "   float op_TestElu_alpha = 0.100000001;\n",
            "\n",
            "//------ ELU CUDA\n",
            "   // CUDA kernel for ELU operation\n",
            "   __global__ void op_TestElu_elu_kernel(const float* input, float* output, size_t size, float alpha) {\n",
            "      int idx = blockIdx.x * blockDim.x + threadId...\n",
            "\n",
            "Input tensor:\n",
            "-2.0000 -1.5000 -1.0000 \n",
            "-0.5000 0.0000 0.5000 \n",
            "1.0000 1.5000 2.0000 \n",
            "-0.3000 -0.2000 -0.1000 \n",
            "0.1000 0.2000 0.3000 \n",
            "\n",
            "Expected output tensor (CPU ELU with alpha=0.1000):\n",
            "-0.0865 -0.0777 -0.0632 \n",
            "-0.0393 0.0000 0.5000 \n",
            "1.0000 1.5000 2.0000 \n",
            "-0.0259 -0.0181 -0.0095 \n",
            "0.1000 0.2000 0.3000 \n",
            "\n",
            "ELU behavior examples (alpha=0.1000):\n",
            "For x = -1.0: ELU(x) = -0.0632\n",
            "For x = 0.0: ELU(x) = 0.0000\n",
            "For x = 1.0: ELU(x) = 1.0000\n",
            "\n",
            "---- Testing with alpha = 1.0000 ----\n",
            "ELU CUDA: input -> output (alpha=1.0000)\n",
            "\n",
            "Generated CUDA code (excerpt):\n",
            "   float op_TestElu_alpha = 1;\n",
            "\n",
            "//------ ELU CUDA\n",
            "   // CUDA kernel for ELU operation\n",
            "   __global__ void op_TestElu_elu_kernel(const float* input, float* output, size_t size, float alpha) {\n",
            "      int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "     ...\n",
            "\n",
            "Input tensor:\n",
            "-2.0000 -1.5000 -1.0000 \n",
            "-0.5000 0.0000 0.5000 \n",
            "1.0000 1.5000 2.0000 \n",
            "-0.3000 -0.2000 -0.1000 \n",
            "0.1000 0.2000 0.3000 \n",
            "\n",
            "Expected output tensor (CPU ELU with alpha=1.0000):\n",
            "-0.8647 -0.7769 -0.6321 \n",
            "-0.3935 0.0000 0.5000 \n",
            "1.0000 1.5000 2.0000 \n",
            "-0.2592 -0.1813 -0.0952 \n",
            "0.1000 0.2000 0.3000 \n",
            "\n",
            "ELU behavior examples (alpha=1.0000):\n",
            "For x = -1.0: ELU(x) = -0.6321\n",
            "For x = 0.0: ELU(x) = 0.0000\n",
            "For x = 1.0: ELU(x) = 1.0000\n",
            "\n",
            "---- Testing with alpha = 2.0000 ----\n",
            "ELU CUDA: input -> output (alpha=2.0000)\n",
            "\n",
            "Generated CUDA code (excerpt):\n",
            "   float op_TestElu_alpha = 2;\n",
            "\n",
            "//------ ELU CUDA\n",
            "   // CUDA kernel for ELU operation\n",
            "   __global__ void op_TestElu_elu_kernel(const float* input, float* output, size_t size, float alpha) {\n",
            "      int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "     ...\n",
            "\n",
            "Input tensor:\n",
            "-2.0000 -1.5000 -1.0000 \n",
            "-0.5000 0.0000 0.5000 \n",
            "1.0000 1.5000 2.0000 \n",
            "-0.3000 -0.2000 -0.1000 \n",
            "0.1000 0.2000 0.3000 \n",
            "\n",
            "Expected output tensor (CPU ELU with alpha=2.0000):\n",
            "-1.7293 -1.5537 -1.2642 \n",
            "-0.7869 0.0000 0.5000 \n",
            "1.0000 1.5000 2.0000 \n",
            "-0.5184 -0.3625 -0.1903 \n",
            "0.1000 0.2000 0.3000 \n",
            "\n",
            "ELU behavior examples (alpha=2.0000):\n",
            "For x = -1.0: ELU(x) = -1.2642\n",
            "For x = 0.0: ELU(x) = 0.0000\n",
            "For x = 1.0: ELU(x) = 1.0000\n",
            "\n",
            "ELU CUDA operator test completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLVFkmWc9uOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}